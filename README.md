# AI_Avatar
1. Create Text to Text module
   1. Github https://github.com/huggingface/transformers/tree/main/src/transformers/models/blenderbot 
   2. Kaggle https://www.kaggle.com/code/polinakuleshova/blenderbot
   3. [Notebook](blenderbot.ipynb)
2. Image generation
   1. Github https://github.com/NVlabs/stylegan3 
   2. Kaggle https://www.kaggle.com/code/polinakuleshova/stylegan3
   3. [Notebook](stylegan3.ipynb)
3. Use text to speech module
   1. Github https://github.com/Plachtaa/VALL-E-X 
   2. Kaggle https://www.kaggle.com/code/polinakuleshova/vall-e-x?scriptVersionId=213599442
   3. [Notebook](vall-e-x.ipynb)
4. Video generation
   1. Github https://github.com/Stability-AI/generative-models
   2. Kaggle https://www.kaggle.com/code/polinakuleshova/stability
   3. [Notebook](stability.ipynb)
5. Lips-sync
   1. Github https://github.com/TMElyralab/MuseTalk 
   2. Kaggle https://www.kaggle.com/code/polinakuleshova/musetalk 
   3. [Notebook](musetalk.ipynb)
6. MuseV
   1. GitHub https://github.com/TMElyralab/MuseV
   2. Used for the demonstration.
   3. This model uses Diffusion model [notebook](stability.ipynb). As the model was too large to run even on Kaggle, we used the resylts for eye-movements from the official repository [link](https://github.com/TMElyralab/MuseV?tab=readme-ov-file#human)
